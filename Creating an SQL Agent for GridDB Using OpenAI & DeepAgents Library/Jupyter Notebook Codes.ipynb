{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f952326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "889ac213",
   "metadata": {},
   "source": [
    "## Importing and Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "924632ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU deepagents\n",
    "%pip install -qU langgraph\n",
    "%pip install -qU langchain-openai\n",
    "%pip install -qU pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6f4f4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from deepagents import create_deep_agent\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a92eb08",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ec050cf",
   "metadata": {},
   "source": [
    "### Establishing a Connection with GridDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0a71f66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "username = os.environ.get(\"username\")\n",
    "password = os.environ.get(\"password\")\n",
    "base_url = os.environ.get(\"base_url\")\n",
    "\n",
    "\n",
    "url = f\"{base_url}/checkConnection\"\n",
    "\n",
    "credentials = f\"{username}:{password}\"\n",
    "encoded_credentials = base64.b64encode(credentials.encode()).decode()\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',  # Added this header to specify JSON content\n",
    "    'Authorization': f'Basic {encoded_credentials}',\n",
    "    'User-Agent': 'PostmanRuntime/7.29.0'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa94c4f",
   "metadata": {},
   "source": [
    "## Creating a LangGraph Deep Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96334859",
   "metadata": {},
   "source": [
    "### Simple Example of DeepAgent Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535bd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_db query= SELECT * FROM patients WHERE days_in_hospital > 5;\n"
     ]
    }
   ],
   "source": [
    "def search_db(query: str) -> str:\n",
    "    \"\"\"\n",
    "    This tool searches the GridDB database using the provided SQL query.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"search_db query=\", query)\n",
    "\n",
    "system_instructions = \"\"\"\n",
    "\n",
    "<role>\n",
    "You are an SQL expert and you have access to a GridDB database. You can use the tool below to search the database using SQL queries. \n",
    "When you receive a user query, you should formulate an appropriate SQL query to retrieve the relevant information from the database.\n",
    "</role>\n",
    "\n",
    "<tools>\n",
    "** search_db**: \n",
    "- This tool allows you to search the GridDB database using SQL queries.\n",
    "- Input to this tool should be a valid SQL query string.\n",
    "- The output of this tool will be the results of the SQL query.\n",
    "</tools>\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", \n",
    "                 temperature=0)\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    tools=[search_db],\n",
    "    instructions=system_instructions,\n",
    "    model=llm\n",
    ")\n",
    "\n",
    "# Invoke the agent\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \n",
    "                                     \"content\": \"Select the patients who spent more than 5 days in the hospital.\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a326c",
   "metadata": {},
   "source": [
    "### Defining tools for GridDB SQL Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6698c95f",
   "metadata": {},
   "source": [
    "#### Tools for Inserting CSV file into GridDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4688fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_csv_to_griddb(csv_file_path: str) -> str:\n",
    "\n",
    "    \"\"\"\n",
    "    This tool inserts data from a CSV file into the GridDB database.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file to be inserted.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        if not os.path.isfile(csv_file_path):\n",
    "            return f\"Error: The file '{csv_file_path}' does not exist.\"\n",
    "\n",
    "        dataset = pd.read_csv(csv_file_path)\n",
    "\n",
    "        container_name = Path(csv_file_path).stem\n",
    "\n",
    "        ## =============================\n",
    "        ## Creating Container for GridDB\n",
    "        ## =============================\n",
    "\n",
    "        dataset.insert(0, \"SerialNo\", dataset.index + 1)\n",
    "        dataset.columns.name = None   \n",
    "        # Mapping pandas dtypes to GridDB types\n",
    "        type_mapping = {\n",
    "            \"int64\":          \"LONG\",\n",
    "            \"float64\":        \"DOUBLE\",\n",
    "            \"bool\":           \"BOOL\",\n",
    "            'datetime64': \"TIMESTAMP\", \n",
    "            \"object\":         \"STRING\",\n",
    "            \"category\":       \"STRING\",\n",
    "        }\n",
    "\n",
    "        # Generate the columns part of the payload dynamically\n",
    "        columns = []\n",
    "        for col, dtype in dataset.dtypes.items():\n",
    "            griddb_type = type_mapping.get(str(dtype), \"STRING\")  # Default to STRING if unknown\n",
    "            columns.append({\n",
    "                \"name\": col,\n",
    "                \"type\": griddb_type\n",
    "            })\n",
    "\n",
    "        url = f\"{base_url}/containers\"\n",
    "        # Create the payload for the POST request\n",
    "        payload = json.dumps({\n",
    "            \"container_name\": container_name,\n",
    "            \"container_type\": \"COLLECTION\",\n",
    "            \"rowkey\": True,  # Assuming the first column as rowkey\n",
    "            \"columns\": columns\n",
    "        })\n",
    "\n",
    "        # Make the POST request to create the container\n",
    "        response = requests.post(url, headers=headers, data=payload)\n",
    "\n",
    "        print(\"Create container response:\", response.status_code, response.text)\n",
    "        if response.status_code != 201:\n",
    "            return f\"Error creating container: {response.text}\"\n",
    "        \n",
    "        ## =============================\n",
    "        ## Inserting data in the container\n",
    "        ## =============================\n",
    "\n",
    "\n",
    "        url = f\"{base_url}/containers/{container_name}/rows\"\n",
    "\n",
    "        def format_row(row):\n",
    "            formatted = []\n",
    "            for item in row:\n",
    "                if pd.isna(item):\n",
    "                    formatted.append(None)  # Convert NaN to None\n",
    "                elif isinstance(item, bool):\n",
    "                    formatted.append(str(item).lower())  # Convert True/False to true/false\n",
    "                elif isinstance(item, (int, float)):\n",
    "                    formatted.append(item)  # Keep integers and floats as they are\n",
    "                else:\n",
    "                    formatted.append(str(item))  # Convert other types to string\n",
    "            return formatted\n",
    "\n",
    "        # Prepare rows with correct formatting\n",
    "        rows = [format_row(row) for row in dataset.values.tolist()]\n",
    "\n",
    "        # Create payload as a JSON string\n",
    "        payload = json.dumps(rows)\n",
    "\n",
    "        # Make the PUT request to add the rows to the container\n",
    "        response = requests.put(url, headers=headers, data=payload)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return f\"Error inserting data: {response.text}\"                 \n",
    "\n",
    "        \n",
    "        return f\"Data inserted successfully in the container {container_name}\"\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044fd90",
   "metadata": {},
   "source": [
    "#### Tool for Retrieving Container Columns from GridDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f83490c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_container_columns(container_name: str) -> list[str] | str:\n",
    "\n",
    "    \"\"\"\n",
    "    Fetches one row from the container and tries to get column names from response metadata\n",
    "    Use this tool before executing any CRUD query to get the column names\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not container_name:\n",
    "            return \"Error: container_name must be provided\"\n",
    "        \n",
    "        url = f\"{base_url}/containers/{container_name}/rows\"\n",
    "        \n",
    "        payload = {\n",
    "            \"offset\": 0,\n",
    "            \"limit\": 1,\n",
    "            \"condition\": \"\",\n",
    "            \"sort\": \"\"\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        if response.status_code != 200:\n",
    "            return f\"Error fetching rows for container {container_name}: {response.status_code} {response.text}\"\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        rows = data.get(\"rows\", None)\n",
    "        if rows is None or len(rows) == 0:\n",
    "            return f\"No rows returned from container {container_name}\"\n",
    "        \n",
    "        # Try to get “columns” metadata from response, if present\n",
    "        if \"columns\" in data and isinstance(data[\"columns\"], list):\n",
    "            cols_meta = data[\"columns\"]\n",
    "            # cols_meta: list of dicts with at least \"name\"\n",
    "            names = [col_meta.get(\"name\", \"\") for col_meta in cols_meta]\n",
    "            return names\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab38f6c0",
   "metadata": {},
   "source": [
    "#### Tool for Retrieving Data from GridDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f1fcd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sql_select_from_griddb(container_name: str, sql_stmt: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute a SQL SELECT query on a GridDB Cloud container via Web API,\n",
    "    and return a formatted string of the results.\n",
    "\n",
    "    If the result is an aggregate (e.g. COUNT, SUM etc.) returning a single value,\n",
    "    returns something like \"Aggregate result: 42\".\n",
    "\n",
    "    Otherwise, returns record by record detail.\n",
    "    \"\"\"\n",
    "    print(\"sql_select_from_griddb query =\", sql_stmt)\n",
    "    \n",
    "    try:\n",
    "        if not container_name:\n",
    "            return \"Error: container_name must be provided\"\n",
    "        if not sql_stmt.strip():\n",
    "            return \"Error: SQL statement must be provided\"\n",
    "        \n",
    "        url = f\"{base_url}/sql\"\n",
    "        payload = [\n",
    "            {\n",
    "                \"type\": \"sql-select\",\n",
    "                \"stmt\": sql_stmt\n",
    "            }\n",
    "        ]\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        if response.status_code != 200:\n",
    "            return f\"Error executing SQL: {response.status_code}, {response.text}\"\n",
    "        \n",
    "        resp_json = response.json()\n",
    "        if not isinstance(resp_json, list) or len(resp_json) < 1:\n",
    "            return f\"Unexpected response format: {resp_json}\"\n",
    "        \n",
    "        first = resp_json[0]\n",
    "        columns_meta = first.get(\"columns\")\n",
    "        results = first.get(\"results\")\n",
    "        \n",
    "        # Handle case of aggregate queries (when there are columns but rows are empty OR rows missing)\n",
    "        # Or when results is present but format is such that we have just one value\n",
    "        if columns_meta is not None and results is not None:\n",
    "            # If only one column and one row, could be an aggregate\n",
    "            if len(results) == 1 and len(columns_meta) == 1:\n",
    "                # e.g. [{\"name\":\"count\", \"type\":\"LONG\"}] and [[42]]\n",
    "                col_name = columns_meta[0].get(\"name\", \"value\")\n",
    "                val = results[0][0]\n",
    "                return f\"{col_name}: {val}\"\n",
    "            \n",
    "            # Otherwise, return record by record\n",
    "            output_lines = []\n",
    "            for idx, row in enumerate(results, start=1):\n",
    "                output_lines.append(f\"=============================\")\n",
    "                output_lines.append(f\"Record {idx}\")\n",
    "                for col_meta, cell in zip(columns_meta, row):\n",
    "                    col_name = col_meta.get(\"name\", \"UnknownColumn\")\n",
    "                    cell_str = \"None\" if cell is None else str(cell)\n",
    "                    output_lines.append(f\"{col_name}: {cell_str}\")\n",
    "                output_lines.append(\"\")  # blank line between records\n",
    "            output = \"\\n\".join(output_lines)\n",
    "            return output\n",
    "        \n",
    "        # If no \"results\", but maybe \"columns\" and maybe some other field like \"rows\" or \"rows/records\"\n",
    "        # Fallback: inspect other fields\n",
    "        # For example, if the response has a field \"rows\" (old format) or \"values\"\n",
    "        # you can try to fetch those.\n",
    "        \n",
    "        # If still nothing meaningful:\n",
    "        return f\"No usable result data found for query: {first}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001289df",
   "metadata": {},
   "source": [
    "#### Tool for Inserting and Updating Data in GridDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b8abd7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_insert_update_griddb(container_name: str, sql_stmt: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute an SQL INSERT or UPDATE query on GridDB Cloud via Web API,\n",
    "    return a message indicating success or error.\n",
    "    \n",
    "    Args:\n",
    "        container_name (str): Name of the container/table (used for readability/logging).\n",
    "        sql_stmt (str): The full SQL INSERT or UPDATE statement to execute.\n",
    "    \n",
    "    Returns:\n",
    "        A string: either success message or error.\n",
    "    \"\"\"\n",
    "    print(\"sql_update_griddb query =\", sql_stmt)\n",
    "    \n",
    "    try:\n",
    "        if not container_name:\n",
    "            return \"Error: container_name must be provided\"\n",
    "        if not sql_stmt.strip():\n",
    "            return \"Error: SQL statement must be provided\"\n",
    "        \n",
    "        # Construct the URL for SQL update (inserts or updates)\n",
    "        url = f\"{base_url}/sql/update\"\n",
    "        \n",
    "        payload = [\n",
    "            {\n",
    "                \"stmt\": sql_stmt\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return f\"Error executing SQL update: {response.status_code}, {response.text}\"\n",
    "        \n",
    "        # The response may or may not include useful JSON; check and return appropriate message\n",
    "        try:\n",
    "            resp_json = response.json()\n",
    "        except ValueError:\n",
    "            # Not JSON; maybe empty or plaintext\n",
    "            return f\"SQL update executed successfully for container '{container_name}'.\"\n",
    "        \n",
    "        # If JSON and maybe return shows how many rows affected or similar\n",
    "        # Depending on what the API returns; adapt as needed\n",
    "        if isinstance(resp_json, list) and len(resp_json) > 0:\n",
    "            # Some APIs give back something like [{\"count\": N}] or status info\n",
    "            # Try to find a count or status field\n",
    "            first = resp_json[0]\n",
    "            if \"count\" in first:\n",
    "                return f\"Successfully updated/inserted {first['count']} rows into '{container_name}'.\"\n",
    "            else:\n",
    "                # If no 'count', just return the JSON for debugging\n",
    "                return f\"SQL update successful. Response: {resp_json}\"\n",
    "        else:\n",
    "            return f\"SQL update successful into container '{container_name}'.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dda2d5",
   "metadata": {},
   "source": [
    "#### Tool for Deleting Data From GridDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e7077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_delete_rows_griddb(container_name: str, row_keys: list, convert_to_int: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Delete one or more rows from a GridDB container via Web API.\n",
    "\n",
    "    Args:\n",
    "        container_name (str): the container to delete from.\n",
    "        row_keys (list): list of rowkey values (as str or int). This can be retrieved by first calling the selectsql_select_from_griddb tool to get the rowkeys.\n",
    "        convert_to_int (bool): if True, try converting keys to ints, else keep as given.\n",
    "\n",
    "    Returns:\n",
    "        A message string: success or detailed error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not container_name:\n",
    "            return \"Error: container_name must be provided\"\n",
    "        if not row_keys or not isinstance(row_keys, list):\n",
    "            return \"Error: row_keys must be a non-empty list\"\n",
    "        \n",
    "        # Convert types if needed\n",
    "        if convert_to_int:\n",
    "            # only convert those that are numeric strings\n",
    "            new_keys = []\n",
    "            for k in row_keys:\n",
    "                try:\n",
    "                    ki = int(k)\n",
    "                    new_keys.append(ki)\n",
    "                except Exception:\n",
    "                    # If conversion fails, keep original\n",
    "                    new_keys.append(k)\n",
    "            row_keys_to_use = new_keys\n",
    "        else:\n",
    "            row_keys_to_use = row_keys\n",
    "\n",
    "        print(\"sql_delete_rows_griddb using row_keys =\", row_keys_to_use)\n",
    "\n",
    "        url = f\"{base_url}/containers/{container_name}/rows\"\n",
    "        response = requests.delete(url, headers=headers, json=row_keys_to_use)\n",
    "\n",
    "        print(\"DELETE response status:\", response.status_code)\n",
    "        print(\"DELETE response text:\", response.text)\n",
    "\n",
    "        # Acceptable success statuses\n",
    "        if response.status_code not in (200, 204):\n",
    "            return f\"Error deleting rows: {response.status_code}, {response.text}\"\n",
    "\n",
    "        return f\"Successfully requested delete of {len(row_keys_to_use)} row(s) from '{container_name}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bc4006",
   "metadata": {},
   "source": [
    "### Create a Deep Agent for Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_instructions = \"\"\"\n",
    "\n",
    "<role>\n",
    "You are an SQL expert and you have access to a GridDB database. You can use the tool below to search the database using SQL queries. \n",
    "When you receive a user query, you should formulate an appropriate SQL query to retrieve the relevant information from the database.\n",
    "</role>\n",
    "\n",
    "<tools>\n",
    "** insert_csv_to_griddb**: \n",
    "- This tool allows you to insert data from a CSV file into the GridDB database.\n",
    "- Input to this tool should be the path to a valid CSV file or the name of the CSV file. The tool will add the .csv extension if not provided.\n",
    "- The tool returns a success message or an error message.\n",
    "\n",
    "** get_container_columns**:\n",
    "- This tool fetches the name of all columns in the specified container.\n",
    "- Input to this tool should be the name of the container (table).\n",
    "- The tool returns a list of column names or an error message.\n",
    "\n",
    "** sql_select_from_griddb**:\n",
    "- This tool allows you to search the GridDB database using SQL queries.\n",
    "- Input to this tool should be a valid SQL query string.\n",
    "- The output of this tool will be the results of the SQL query.\n",
    "\n",
    "** sql_insert_update_griddb**:\n",
    "- This tool allows you to insert or update data in the GridDB database using SQL queries.\n",
    "- Input to this tool should be a valid SQL INSERT or UPDATE query string.\n",
    "- The output of this tool will be a success message or an error message.\n",
    "\n",
    "** sql_delete_rows_griddb**:\n",
    "- This tool allows you to delete one or more rows from a GridDB container using their rowkey values.\n",
    "- Input to this tool should be the name of the container (table) and a list of rowkey values identifying the rows to delete.\n",
    "- Always retrieve the rowkeys by first calling the `sql_select_from_griddb` tool to get the rowkeys.\n",
    "- The output of this tool will be a success message or an error message.\n",
    "\n",
    "</tools>\n",
    "\n",
    "\n",
    "<constraints>\n",
    "- When using the insert_csv_to_griddb tool, ensure that the CSV file exists in the current working directory or provide the full path to the file.\n",
    "- Always use the get_container_columns tool to retrieve column names before constructing SQL queries to avoid errors.\n",
    "- Ensure that SQL queries are syntactically correct and reference existing containers and columns in the database.\n",
    "- Before using the sql_delete_rows_griddb tool, always retrieve the rowkeys by first calling the sql_select_from_griddb tool to get the rowkeys.\n",
    "</constraints>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", \n",
    "                 temperature=0)\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    tools=[insert_csv_to_griddb, \n",
    "           get_container_columns,\n",
    "           sql_select_from_griddb,\n",
    "           sql_insert_update_griddb,\n",
    "           sql_delete_rows_griddb],\n",
    "    instructions=system_instructions,\n",
    "    model=llm\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf63e1",
   "metadata": {},
   "source": [
    "### Testing the GridDB SQL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "db450a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(query: str) -> str:\n",
    "    # Invoke the agent\n",
    "    result = agent.invoke({\"messages\": [{\"role\": \"user\", \n",
    "                                         \"content\": query}]})\n",
    "    return result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "967ee15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create container response: 201 \n",
      "The `titanic_dataset.csv` file has been successfully inserted into the database. If you need any further assistance or queries regarding this dataset, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\"Insert the titanic_dataset.csv file into the database\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6bc2a0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column names in the `titanic_dataset` table are:\n",
      "\n",
      "1. SerialNo\n",
      "2. PassengerId\n",
      "3. Survived\n",
      "4. Pclass\n",
      "5. Name\n",
      "6. Sex\n",
      "7. Age\n",
      "8. SibSp\n",
      "9. Parch\n",
      "10. Ticket\n",
      "11. Fare\n",
      "12. Cabin\n",
      "13. Embarked\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\"What are the column names in the titanic_dataset table?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f546ac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_select_from_griddb query = SELECT Name, Age FROM titanic_dataset WHERE Age IS NOT NULL ORDER BY Age DESC LIMIT 3\n",
      "The names and ages of the top 3 oldest passengers in the Titanic dataset are:\n",
      "\n",
      "1. **Barkworth, Mr. Algernon Henry Wilson** - Age: 80.0\n",
      "2. **Svensson, Mr. Johan** - Age: 74.0\n",
      "3. **Artagaveytia, Mr. Ramon** - Age: 71.0\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\"Get the names and ages of the top 3 oldest passengers in the titanic_dataset\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "19758a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_select_from_griddb query = SELECT (COUNT(Survived) FILTER (WHERE Survived = 1) * 100.0 / COUNT(Survived)) AS Survival_Percentage FROM titanic_dataset\n",
      "sql_select_from_griddb query = SELECT (SUM(CASE WHEN Survived = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(Survived)) AS Survival_Percentage FROM titanic_dataset\n",
      "The percentage of passengers who survived in the Titanic dataset is approximately 38.38%.\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\"What is the percentage of passengers who survived in the titanic_dataset?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0ccdebad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total passengers: 891\n",
      "Number who survived: 342\n",
      "Percentage who survived: 38.38%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"titanic_dataset.csv\")\n",
    "\n",
    "# Drop any rows where \"Survived\" is missing (if applicable)\n",
    "df2 = df.dropna(subset=[\"Survived\"])\n",
    "\n",
    "total = len(df2)\n",
    "survived = df2[\"Survived\"].sum()  # assuming Survived is 1 for survived, 0 for not\n",
    "\n",
    "percentage_survived = survived / total * 100\n",
    "\n",
    "print(f\"Total passengers: {total}\")\n",
    "print(f\"Number who survived: {survived}\")\n",
    "print(f\"Percentage who survived: {percentage_survived:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "dcc727b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_update_griddb query = INSERT INTO titanic_dataset (PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked) VALUES (NULL, NULL, 3, 'John Doe', 'male', 89, 0, 0, 'A123', 7.25, NULL, 'S')\n",
      "sql_select_from_griddb query = SELECT MAX(SerialNo) AS MaxSerialNo FROM titanic_dataset\n",
      "sql_update_griddb query = INSERT INTO titanic_dataset (SerialNo, PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked) VALUES (892, NULL, NULL, 3, 'John Doe', 'male', 89, 0, 0, 'A123', 7.25, NULL, 'S')\n",
      "The new passenger \"John Doe\" has been successfully added to the `titanic_dataset` with a `SerialNo` of 892. If you need any further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\"\"\"\n",
    "                        Insert a new passenger in the titanic_dataset. \n",
    "                        He is a 89 years old male named \"John Doe\",\n",
    "                        with passenger class 3, embarked from Southampton,\n",
    "                        having 0 siblings/spouses aboard, 0 parents/children aboard,\n",
    "                        ticket number \"A123\", fare 7.25, cabin as NULL\n",
    "                        \"\"\"\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "63bd9711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_select_from_griddb query = SELECT Name, Age FROM titanic_dataset WHERE Age IS NOT NULL ORDER BY Age DESC LIMIT 1\n",
      "The oldest passenger in the Titanic dataset is John Doe, who was 89 years old.\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\"Who is the oldest passenger in the titanic_dataset?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "da7267d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_select_from_griddb query = SELECT MAX(Age) AS OldestAge FROM titanic_dataset\n",
      "sql_update_griddb query = UPDATE titanic_dataset SET Age = 95 WHERE Age = 89\n",
      "The age of the oldest passenger in the titanic_dataset has been successfully updated to 95. If you have any more requests or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\"Update the age of the oldest passenger in the titanic_dataset to 95\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6ba7369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_select_from_griddb query = SELECT * FROM titanic_dataset WHERE Age = (SELECT MAX(Age) FROM titanic_dataset)\n",
      "The oldest passenger in the Titanic dataset is John Doe, a 95-year-old male. He was in the third class, with a ticket number A123, and embarked from Southampton (Embarked: S).\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\"Who is the oldest passenger in the titanic_dataset?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a34247ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_select_from_griddb query = SELECT SerialNo FROM titanic_dataset WHERE Age < 30\n",
      "sql_delete_rows_griddb using row_keys = [1, 3, 8, 9, 10, 11, 13, 15, 17, 23, 24, 25, 28, 35, 38, 39, 40, 42, 44, 45, 50, 51, 52, 54, 57, 58, 59, 60, 61, 64, 67, 68, 69, 70, 72, 73, 74, 76, 79, 81, 82, 84, 85, 87, 89, 90, 91, 92, 94, 98, 101, 103, 106, 107, 112, 113, 114, 115, 116, 118, 119, 120, 121, 126, 128, 132, 134, 135, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 148, 152, 157, 163, 164, 165, 166, 170, 172, 173, 174, 176, 183, 184, 185, 192, 193, 194, 200, 201, 205, 206, 208, 209, 211, 213, 217, 221, 222, 226, 227, 228, 229, 232, 234, 235, 238, 239, 243, 244, 247, 248, 252, 256, 262, 267, 268, 272, 279, 282, 283, 284, 288, 290, 291, 292, 294, 295, 297, 298, 303, 306, 308, 311, 312, 313, 314, 316, 317, 321, 322, 324, 330, 334, 337, 341, 342, 343, 344, 346, 349, 351, 353, 354, 356, 357, 362, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 382, 386, 387, 390, 392, 393, 394, 395, 396, 399, 400, 402, 403, 404, 405, 408, 409, 418, 420, 422, 423, 424, 425, 427, 428, 431, 434, 436, 437, 438, 442, 443, 444, 446, 447, 449, 456, 470, 474, 475, 478, 479, 480, 481, 485, 490, 492, 495, 499, 500, 501, 502, 505, 506, 509, 510, 511, 515, 522, 530, 531, 533, 536, 540, 542, 543, 547, 550, 551, 552, 554, 555, 563, 566, 567, 568, 575, 576, 581, 586, 589, 601, 608, 609, 616, 618, 619, 620, 621, 623, 624, 625, 628, 629, 635, 636, 641, 642, 643, 645, 647, 650, 652, 653, 655, 656, 659, 665, 667, 676, 677, 678, 682, 683, 684, 686, 687, 688, 689, 690, 692, 694, 701, 703, 704, 705, 709, 711, 714, 716, 718, 721, 722, 725, 726, 729, 730, 731, 732, 734, 735, 736, 743, 744, 747, 749, 751, 752, 754, 756, 757, 758, 763, 765, 771, 776, 778, 781, 782, 783, 785, 786, 787, 788, 789, 792, 795, 803, 804, 805, 808, 811, 814, 817, 820, 822, 824, 825, 828, 831, 832, 834, 835, 837, 841, 842, 845, 849, 851, 853, 854, 856, 859, 862, 865, 867, 870, 871, 875, 876, 877, 878, 881, 883, 884, 885, 887, 888, 890]\n",
      "DELETE response status: 204\n",
      "DELETE response text: \n",
      "All passengers younger than 30 years have been successfully deleted from the `titanic_dataset`. If you have any more requests or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\"Delete all the passengers younger than 30 years in the titanic_dataset\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cf3e6dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_select_from_griddb query = SELECT COUNT(PassengerId) FROM titanic_dataset\n",
      "The total number of passengers in the titanic_dataset is 507.\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\"what is the total number of passengers in the titanic_dataset?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f5465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_env (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
